{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "caliber-basic-model-trial.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "98f358c10a29418482622c1c24cbe8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1dbbcd24c514d8aa0a002963442b6cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_570706732098418d853c20d890ef4e1f",
              "IPY_MODEL_ab64fcf2b1eb4bbc9016a3376f71569f",
              "IPY_MODEL_629895d515ec4857a9de4571dd8f798e"
            ]
          }
        },
        "d1dbbcd24c514d8aa0a002963442b6cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "570706732098418d853c20d890ef4e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0432fc53333c4094ac1876fba9e5397a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ff2368bdb6946448bf576882df7fcc0"
          }
        },
        "ab64fcf2b1eb4bbc9016a3376f71569f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0b5683ca2614c3c903100a06db3e2cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 167502836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 167502836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d7f9ffa5567495ca182c5fb8b1b1e70"
          }
        },
        "629895d515ec4857a9de4571dd8f798e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7fc23311d3f849d48314152eefebe5c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 160M/160M [00:03&lt;00:00, 51.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5665a54e2aa4d12bcb1452746f16b55"
          }
        },
        "0432fc53333c4094ac1876fba9e5397a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ff2368bdb6946448bf576882df7fcc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0b5683ca2614c3c903100a06db3e2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d7f9ffa5567495ca182c5fb8b1b1e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7fc23311d3f849d48314152eefebe5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5665a54e2aa4d12bcb1452746f16b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c53883a769e4816bbec01dd380aec83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9721447cc953443bbe82dca4b0b62486",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01306ecb380143dd8062f01cbcd41afe",
              "IPY_MODEL_beeb9542f95244de82fef2ed1aef41b9",
              "IPY_MODEL_61575573f8214537868cfe0966507143"
            ]
          }
        },
        "9721447cc953443bbe82dca4b0b62486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01306ecb380143dd8062f01cbcd41afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2414ce0d4fb34b2bb99eab5f42f2d589",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc012b89b8634277bd617e55a01e870e"
          }
        },
        "beeb9542f95244de82fef2ed1aef41b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bba14996a9b642b4b28e01fe8bbe8fb8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77844807,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77844807,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8091108683944bf09d103decb1791615"
          }
        },
        "61575573f8214537868cfe0966507143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83d354f4eafc43f589eabd2ab543bee2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 74.2M/74.2M [00:00&lt;00:00, 105MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb4e7a56cb164da08248b5bee6b9cfce"
          }
        },
        "2414ce0d4fb34b2bb99eab5f42f2d589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc012b89b8634277bd617e55a01e870e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bba14996a9b642b4b28e01fe8bbe8fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8091108683944bf09d103decb1791615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83d354f4eafc43f589eabd2ab543bee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb4e7a56cb164da08248b5bee6b9cfce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abea681863294730955d34313bbf79be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_66f2acf85c6d465b887964da6471ca20",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d30a625ec18d43c7a0c5d0056cd7b0d3",
              "IPY_MODEL_7afdb15959d749db83af85587585a901",
              "IPY_MODEL_634c18ace7be452581c1821c5423df8f"
            ]
          }
        },
        "66f2acf85c6d465b887964da6471ca20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d30a625ec18d43c7a0c5d0056cd7b0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8806dff22354b3a9ad85be75f76f498",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b640a0dff19492b9eebc2a628877b68"
          }
        },
        "7afdb15959d749db83af85587585a901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfa41288d6ac434a88540ab9c87f7427",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 178090079,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 178090079,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d183128f7c9e47cba8607d7c3a53a476"
          }
        },
        "634c18ace7be452581c1821c5423df8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b36c1e610c7d47368ffe68e49976e071",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170M/170M [00:03&lt;00:00, 52.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5abedc71d23c4cb0adae2bdd6307842a"
          }
        },
        "c8806dff22354b3a9ad85be75f76f498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b640a0dff19492b9eebc2a628877b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfa41288d6ac434a88540ab9c87f7427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d183128f7c9e47cba8607d7c3a53a476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b36c1e610c7d47368ffe68e49976e071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5abedc71d23c4cb0adae2bdd6307842a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79zfhRZAyCdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "896a4f2a-e451-44cd-ad07-4ef75e497b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# 구글 드라이브 접근\n",
        "ROOT = \"/content/drive\"\n",
        "try:\n",
        "  drive.mount(ROOT, force_remount=True)\n",
        "except:\n",
        "  drive.mount(ROOT)\n",
        "\n",
        "# 본인 경로에 맞게 수정하면 됨.\n",
        "PATH = os.path.join(ROOT, \"MyDrive/Task/plastic-segmentation/Data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqJ5Eqm9eNG"
      },
      "source": [
        "## install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BwRCv9o9F-l",
        "outputId": "b0e514d5-228b-4804-f7ae-b529c3f3020d"
      },
      "source": [
        "%%shell\n",
        " \n",
        "pip install cython\n",
        "# Install pycocotools, the version by default in Colab\n",
        "# has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n",
        "pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.24)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-edop8a0s\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-edop8a0s\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.24)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=263923 sha256=3801b2ccd2e7cd23bd709241f42538108c27d50bfe9f2d6ef60a79ea38c8adea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-20j_vs8e/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.3\n",
            "    Uninstalling pycocotools-2.0.3:\n",
            "      Successfully uninstalled pycocotools-2.0.3\n",
            "Successfully installed pycocotools-2.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjUUdyqH9L-Q",
        "outputId": "73a4e4af-3b51-4d63-e557-bc7b59685412"
      },
      "source": [
        "%%shell\n",
        "# download the Penn-Fudan dataset\n",
        "wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip .\n",
        "# extract it in the current folder\n",
        "unzip PennFudanPed.zip\n",
        "rm PennFudanPed.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 05:27:01--  https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip\n",
            "Resolving www.cis.upenn.edu (www.cis.upenn.edu)... 158.130.69.163, 2607:f470:8:64:5ea5::d\n",
            "Connecting to www.cis.upenn.edu (www.cis.upenn.edu)|158.130.69.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53723336 (51M) [application/zip]\n",
            "Saving to: ‘PennFudanPed.zip’\n",
            "\n",
            "PennFudanPed.zip    100%[===================>]  51.23M  68.8MB/s    in 0.7s    \n",
            "\n",
            "2021-12-10 05:27:02 (68.8 MB/s) - ‘PennFudanPed.zip’ saved [53723336/53723336]\n",
            "\n",
            "--2021-12-10 05:27:02--  http://./\n",
            "Resolving . (.)... failed: No address associated with hostname.\n",
            "wget: unable to resolve host address ‘.’\n",
            "FINISHED --2021-12-10 05:27:02--\n",
            "Total wall clock time: 1.0s\n",
            "Downloaded: 1 files, 51M in 0.7s (68.8 MB/s)\n",
            "Archive:  PennFudanPed.zip\n",
            "   creating: PennFudanPed/\n",
            "  inflating: PennFudanPed/added-object-list.txt  \n",
            "   creating: PennFudanPed/Annotation/\n",
            "  inflating: PennFudanPed/Annotation/FudanPed00001.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00002.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00003.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00004.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00005.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00006.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00007.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00008.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00009.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00010.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00011.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00012.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00013.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00014.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00015.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00016.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00017.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00018.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00019.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00020.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00021.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00022.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00023.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00024.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00025.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00026.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00027.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00028.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00029.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00030.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00031.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00032.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00033.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00034.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00035.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00036.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00037.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00038.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00039.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00040.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00041.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00042.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00043.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00044.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00045.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00046.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00047.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00048.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00049.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00050.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00051.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00052.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00053.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00054.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00055.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00056.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00057.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00058.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00059.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00060.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00061.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00062.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00063.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00064.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00065.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00066.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00067.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00068.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00069.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00070.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00071.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00072.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00073.txt  \n",
            "  inflating: PennFudanPed/Annotation/FudanPed00074.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00001.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00002.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00003.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00004.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00005.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00006.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00007.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00008.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00009.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00010.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00011.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00012.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00013.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00014.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00015.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00016.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00017.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00018.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00019.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00020.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00021.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00022.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00023.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00024.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00025.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00026.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00027.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00028.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00029.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00030.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00031.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00032.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00033.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00034.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00035.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00036.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00037.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00038.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00039.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00040.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00041.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00042.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00043.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00044.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00045.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00046.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00047.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00048.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00049.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00050.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00051.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00052.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00053.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00054.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00055.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00056.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00057.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00058.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00059.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00060.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00061.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00062.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00063.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00064.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00065.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00066.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00067.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00068.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00069.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00070.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00071.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00072.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00073.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00074.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00075.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00076.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00077.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00078.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00079.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00080.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00081.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00082.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00083.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00084.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00085.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00086.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00087.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00088.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00089.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00090.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00091.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00092.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00093.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00094.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00095.txt  \n",
            "  inflating: PennFudanPed/Annotation/PennPed00096.txt  \n",
            "   creating: PennFudanPed/PedMasks/\n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00001_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00002_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00003_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00004_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00005_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00006_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00007_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00008_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00009_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00010_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00011_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00012_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00013_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00014_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/FudanPed00015_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00016_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00017_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/FudanPed00018_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00019_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00020_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00021_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00022_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00023_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00024_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00025_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00026_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00027_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/FudanPed00028_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00029_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00030_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00031_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00032_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00033_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00034_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00035_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00036_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00037_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00038_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00039_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00040_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00041_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00042_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00043_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00044_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00045_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00046_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00047_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00048_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00049_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00050_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00051_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00052_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00053_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00054_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00055_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00056_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00057_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00058_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00059_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00060_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00061_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00062_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00063_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00064_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00065_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00066_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00067_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00068_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00069_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00070_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00071_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00072_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00073_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/FudanPed00074_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00001_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00002_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00003_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00004_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00005_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00006_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00007_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00008_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00009_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00010_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00011_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00012_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00013_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00014_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00015_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00016_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00017_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00018_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00019_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00020_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00021_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00022_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00023_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00024_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00025_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00026_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00027_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00028_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00029_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00030_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00031_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00032_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00033_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00034_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00035_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00036_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00037_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00038_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00039_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00040_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00041_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00042_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00043_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00044_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00045_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00046_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00047_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00048_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00049_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00050_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00051_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00052_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00053_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00054_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00055_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00056_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00057_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00058_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00059_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00060_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00061_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00062_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00063_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00064_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00065_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00066_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00067_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00068_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00069_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00070_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00071_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00072_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00073_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00074_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00075_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00076_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00077_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00078_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00079_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00080_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00081_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00082_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00083_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00084_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00085_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00086_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00087_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00088_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00089_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00090_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00091_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00092_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00093_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00094_mask.png  \n",
            "  inflating: PennFudanPed/PedMasks/PennPed00095_mask.png  \n",
            " extracting: PennFudanPed/PedMasks/PennPed00096_mask.png  \n",
            "   creating: PennFudanPed/PNGImages/\n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00001.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00002.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00003.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00004.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00005.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00006.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00007.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00008.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00009.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00010.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00011.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00012.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00013.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00014.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00015.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00016.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00017.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00018.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00019.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00020.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00021.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00022.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00023.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00024.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00025.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00026.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00027.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00028.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00029.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00030.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00031.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00032.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00033.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00034.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00035.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00036.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00037.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00038.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00039.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00040.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00041.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00042.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00043.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00044.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00045.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00046.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00047.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00048.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00049.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00050.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00051.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00052.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00053.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00054.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00055.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00056.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00057.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00058.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00059.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00060.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00061.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00062.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00063.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00064.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00065.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00066.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00067.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00068.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00069.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00070.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00071.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00072.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00073.png  \n",
            "  inflating: PennFudanPed/PNGImages/FudanPed00074.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00001.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00002.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00003.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00004.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00005.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00006.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00007.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00008.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00009.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00010.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00011.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00012.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00013.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00014.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00015.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00016.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00017.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00018.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00019.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00020.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00021.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00022.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00023.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00024.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00025.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00026.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00027.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00028.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00029.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00030.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00031.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00032.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00033.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00034.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00035.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00036.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00037.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00038.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00039.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00040.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00041.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00042.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00043.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00044.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00045.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00046.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00047.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00048.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00049.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00050.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00051.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00052.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00053.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00054.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00055.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00056.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00057.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00058.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00059.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00060.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00061.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00062.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00063.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00064.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00065.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00066.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00067.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00068.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00069.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00070.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00071.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00072.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00073.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00074.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00075.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00076.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00077.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00078.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00079.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00080.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00081.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00082.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00083.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00084.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00085.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00086.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00087.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00088.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00089.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00090.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00091.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00092.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00093.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00094.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00095.png  \n",
            "  inflating: PennFudanPed/PNGImages/PennPed00096.png  \n",
            "  inflating: PennFudanPed/readme.txt  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o2zY5KZ9Z-_"
      },
      "source": [
        "* structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4NAjAin9PDM"
      },
      "source": [
        "```tree\n",
        "PennFudanPed/\n",
        "  PedMasks/\n",
        "    FudanPed00001_mask.png\n",
        "    FudanPed00002_mask.png\n",
        "    FudanPed00003_mask.png\n",
        "    FudanPed00004_mask.png\n",
        "    ...\n",
        "  PNGImages/\n",
        "    FudanPed00001.png\n",
        "    FudanPed00002.png\n",
        "    FudanPed00003.png\n",
        "    FudanPed00004.png\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb9KsYao9m0Y"
      },
      "source": [
        "```python\n",
        "from PIL import Image\n",
        "Image.open('PennFudanPed/PNGImages/FudanPed00001.png')\n",
        "mask = Image.open('PennFudanPed/PedMasks/FudanPed00001_mask.png')\n",
        "# each mask instance has a different color, from zero to N, where\n",
        "# N is the number of instances. In order to make visualization easier,\n",
        "# let's adda color palette to the mask.\n",
        "mask.putpalette([\n",
        "    0, 0, 0, # black background\n",
        "    255, 0, 0, # index 1 is red\n",
        "    255, 255, 0, # index 2 is yellow\n",
        "    255, 153, 0, # index 3 is orange\n",
        "])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNKrwIs93pJH",
        "outputId": "0ca1a8dd-bdbf-451e-f953-d064303202b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 62828, done.\u001b[K\n",
            "remote: Counting objects: 100% (2597/2597), done.\u001b[K\n",
            "remote: Compressing objects: 100% (701/701), done.\u001b[K\n",
            "remote: Total 62828 (delta 2260), reused 2078 (delta 1886), pack-reused 60231\u001b[K\n",
            "Receiving objects: 100% (62828/62828), 117.04 MiB | 29.10 MiB/s, done.\n",
            "Resolving deltas: 100% (51034/51034), done.\n",
            "Note: checking out 'v0.3.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at be376084 version check against PyTorch's CUDA version\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "%%shell\n",
        "# Download TorchVision repo to use some files from\n",
        "# references/detection\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        " \n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../\n",
        "# multi-machine, multi-gpu\n",
        "cp references/detection/train.py ../"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Proj-Caliber/Waste-Recycling-Image-Segmentation.git/blob/master/config/CaliberDetector.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNg17tIQ7sro",
        "outputId": "6683df8a-7f92-42a8-ce7c-c65a6cafdc5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CaliberDetector.py'...\n",
            "fatal: repository 'https://github.com/Proj-Caliber/Waste-Recycling-Image-Segmentation.git/blob/master/config/CaliberDetector.py/' not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"basic-model\":\n",
        "  print(\"y\")"
      ],
      "metadata": {
        "id": "SoC17IjV-GVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__name__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp6WfQvS-Qm3",
        "outputId": "a7774226-adb8-42c2-a681-5204ac060cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'__main__'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXGqVo3M-cOQ",
        "outputId": "0931f091-5482-4df2-d93e-b2f43a2e7105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmU1FEV5Pb9W"
      },
      "source": [
        "# init\n",
        "\n",
        "## general flow\n",
        "\n",
        "* Dataset\n",
        "    * CustomDataset\n",
        "    * DataLoaader\n",
        "* Model\n",
        "    * CustomModel\n",
        "    * train\n",
        "    * inference\n",
        "* VSL\n",
        "    * predict(inference)\n",
        "    * output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load utils.py\n",
        "%load transforms.py\n",
        "%load coco_eval.py\n",
        "%load engine.py \n",
        "%load coco_utils.py\n",
        "%load train.py"
      ],
      "metadata": {
        "id": "MKsndCN7q_K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLT8JEvfc4yP"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9t3CnT-gkR8"
      },
      "source": [
        "## libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7DuTJMEKYWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf15f6a-2398-46a2-f7b5-8261ca308e70"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "# import pandas as pd\n",
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch  import nn, Tensor\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# 구글 드라이브 접근\n",
        "ROOT = \"/content/drive\"\n",
        "try:\n",
        "  drive.mount(ROOT, force_remount=True)\n",
        "except:\n",
        "  drive.mount(ROOT)\n",
        "\n",
        "# 본인 경로에 맞게 수정하면 됨.\n",
        "PATH = os.path.join(ROOT, \"MyDrive/Task/plastic-segmentation/Data\")\n",
        "# PATH = os.path.join(ROOT, \"MyDrive/Task/plastic-segmentation/Sample_data\")\n",
        "\n",
        "# 구글 드라이브 경로에서 '/content/sample_data/data\"로 복사 시\n",
        "# shutil.copytree(PATH +\"/train\", \"./sample_data/data/train\")\n",
        "# shutil.copytree(PATH +\"/test\", \"./sample_data/data/test\")\n",
        "\n",
        "# BASE = os.getcwd()\n",
        "# PATH = PATH # gdrive\n",
        "# PATH = f\"{BASE}/sample_data/data\"   # colab\n",
        "# PATH = f\"{BASE}/assets/data\"        # github"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wbbcgOl0hLG"
      },
      "source": [
        "## check sorting path process\n",
        "\n",
        "```python\n",
        "# author : qkrwjdduf159 <pde159@naver.com>\n",
        "# version 1\n",
        "## train\n",
        "trn_path = f\"{PATH}/train/annotation\"\n",
        "file_list = os.listdir(trn_path)\n",
        "\n",
        "train_files = []\n",
        "for file in tqdm(file_list):\n",
        "    dir = trn_path + '/' + file\n",
        "    json_list = glob(dir + '/' + '*.json')\n",
        "    train_files.append(json_list)\n",
        "\n",
        "train_json_list = []\n",
        "for files in tqdm(train_files):\n",
        "    for json_file in tqdm(files):\n",
        "        train_json_list.append(json_file)\n",
        "\n",
        "## test\n",
        "tst_PATH = f\"{PATH}/test/annotations\"\n",
        "file_list = os.listdir(tst_PATH)\n",
        "\n",
        "test_files = []\n",
        "for file in tqdm(file_list):\n",
        "    dir = tst_PATH + '/' + file\n",
        "    json_list = glob(dir + '/' + '*.json')\n",
        "    test_files.append(json_list)\n",
        "\n",
        "test_json_list = []\n",
        "for files in tqdm(test_files):\n",
        "    for json_file in tqdm(files):\n",
        "        test_json_list.append(json_file)\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "# author : AshbeeKim <ksb.forest@gmail.com>\n",
        "# version 2\n",
        "trn = os.path.join(PATH, \"train\")\n",
        "tst = os.path.join(PATH, \"test\")\n",
        "\n",
        "baseDF = {\"kind\" : [], \"label\" : [], \"metainfo_id\" : [], \"feature\" : [], \"image_path\" : [], \"annot_path\": []}\n",
        "trn_num, tst_num = 0, 0\n",
        "for fpath in tqdm([trn, tst]):\n",
        "    kind = os.path.basename(fpath)\n",
        "    BDIR = sorted(os.listdir(fpath))    # image, annotation(s)\n",
        "    for bdir in BDIR:\n",
        "        for dirs in sorted(os.listdir(jn(fpath, bdir))):\n",
        "            dpath = jn(fpath, bdir, dirs)\n",
        "            if bdir.lower()=='image':\n",
        "                paths = sorted(glob(dpath + \"/*.jpg\"))\n",
        "                baseDF['image_path'].extend(paths)\n",
        "                kinds = [kind for cnt in range(len(paths))]\n",
        "                baseDF['kind'].extend(kinds)\n",
        "                if kind=='train' : trn_num += len(paths)\n",
        "                elif kind=='test' : tst_num += len(paths)\n",
        "                fnames = [os.path.basename(fname) for fname in paths]\n",
        "                labels = list(map(lambda x: (x.split('_')[0]), fnames))\n",
        "                baseDF['label'].extend(labels)\n",
        "                metaIds = list(map(lambda x: int(x.split('_')[1]), fnames))\n",
        "                baseDF['metainfo_id'].extend(metaIds)\n",
        "                feats = list(map(lambda x: int(x.split('_')[-1][:-4]), fnames))\n",
        "                baseDF['feature'].extend(feats)\n",
        "            else:\n",
        "                paths = sorted(glob(dpath + \"/*.json\"))\n",
        "                baseDF['annot_path'].extend(paths)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awosI9-Sm-Oz"
      },
      "source": [
        "## Fix Seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggw2ucDIe7CU"
      },
      "source": [
        "# cotributed by @qkrwjdduf156, @AshbeeKim\n",
        "# import libraries\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import json\n",
        "from glob import glob\n",
        "# from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import ToPILImage\n",
        "from torchvision.transforms import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPHxCQsQsF6_"
      },
      "source": [
        "# Fix randomness\n",
        "# * ref : https://www.kaggle.com/rluethy/sartorius-torch-mask-r-cnn\n",
        "\n",
        "def fix_all_seeds(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "fix_all_seeds(513610)\n",
        "\n",
        "data_directory = PATH\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "BATCH_SIZE = 5  # org 1\n",
        "NUM_EPOCHS = 3  # org 5\n",
        "\n",
        "# Reduced the train dataset to 5000 rows\n",
        "TEST = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VtHw_YA57zJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcor3OIe0kUX"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "masks를 확인하고, 다른 값들을 확인한 결과,, \n",
        "* mask 생성 무조건 해야함!!! \n",
        "* 형태(모델을 돌리는 방법)는 자유겠지만, 그 각각을 맞추려면 CustomDataset(default)에서 CustomDataset(multi class or process)로 진행되어야 함.\n",
        "\n",
        "```python\n",
        "0번째 train 이미지\n",
        "\t 이미지 shape : torch.Size([3, 321, 398])\n",
        "\t 이미지 type : torch.FloatTensor\n",
        "\t\tdict_keys == 'boxes' :  \n",
        "\t\t\tshape : torch.Size([1, 4])\n",
        "\t\t\ttype : torch.FloatTensor\n",
        "\t\t\ttensor([[170.,  21., 319., 311.]])\n",
        "\t\tdict_keys == 'labels' :  \n",
        "\t\t\tshape : torch.Size([1])\n",
        "\t\t\ttype : torch.LongTensor\n",
        "\t\t\ttensor([1])\n",
        "\t\tdict_keys == 'masks' :  \n",
        "\t\t\tshape : torch.Size([1, 321, 398])\n",
        "\t\t\ttype : torch.ByteTensor\n",
        "\t\tdict_keys == 'image_id' :  \n",
        "\t\t\tshape : torch.Size([1])\n",
        "\t\t\ttype : torch.LongTensor\n",
        "\t\t\ttensor([155])\n",
        "\t\tdict_keys == 'area' :  \n",
        "\t\t\tshape : torch.Size([1])\n",
        "\t\t\ttype : torch.FloatTensor\n",
        "\t\t\ttensor([43210.])\n",
        "\t\tdict_keys == 'iscrowd' :  \n",
        "\t\t\tshape : torch.Size([1])\n",
        "\t\t\ttype : torch.LongTensor\n",
        "\t\t\ttensor([0])\n",
        "\n",
        "# torch.uint8 -> torch.ByteTensor\n",
        "# torch.float16 -> torch.HalfTensor\n",
        "# torch.float, torch.float32 -> torch.FloatTensor\n",
        "# torch.int16 -> torch.ShortTensor\n",
        "# torch.int, torch.int32 -> torch.IntTensor\n",
        "# torch.int64 -> torch.LongTensor\n",
        "# torch.float64 -> torch.DoubleTensor\n",
        "\n",
        "# list -> tensor ; torch.as_tensor\n",
        "# list\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CaliberDataset.py\n",
        "\n",
        "\n",
        "import cv2 as cv\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# 원래 데이터 intance마다\n",
        "def random_colour_masks(image):\n",
        "    colours = [[0, 255, 0],[0, 0, 255],[255, 0, 0],[0, 255, 255],[255, 255, 0],[255, 0, 255],[80, 70, 180],[250, 80, 190],[245, 145, 50],[70, 150, 250],[50, 190, 190]]\n",
        "    r = np.zeros_like(image).astype(np.uint8)\n",
        "    g = np.zeros_like(image).astype(np.uint8)\n",
        "    b = np.zeros_like(image).astype(np.uint8)\n",
        "    r[image == 1], g[image == 1], b[image == 1] = colours[random.randrange(0,10)]\n",
        "    coloured_mask = np.stack([r, g, b], axis=2)\n",
        "    return coloured_mask \n",
        "\n",
        "def instanceMask(mask, segmentation):\n",
        "    import cv2 as cv\n",
        "    mask = mask.copy()\n",
        "    pts = np.array(segmentation, dtype = np.uint8).reshape(-1, 2)\n",
        "\n",
        "    pts = np.stack([pts, pts, pts])\n",
        "    cv.fillPoly(mask, pts, color=(255, 255, 255))\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root, transforms = None, target_transforms = None, mode = 'train'):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.target_transforms = target_transforms\n",
        "        self.mode = mode.lower()\n",
        "        self.infos = self.baseInfos()\n",
        "        self.imgs, self.annots = self.infos['image_path'], self.infos['annot_path']\n",
        "        # if self.mode == 'train':\n",
        "        #     self.imgs, self.masks = blahblah\n",
        "        self.masks = None\n",
        "\n",
        "    def __getitem__(self, idx=None):\n",
        "        '''return tuple(image, target)'''\n",
        "        image_path = self.imgs[idx]\n",
        "        # # mask 생성 함수보고 고쳐야 할 듯\n",
        "        image = cv.imread(image_path)\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        # C, H, W ==  [H, W, C] >> [N+1, H, W, C] >> [N, H, W]\n",
        "        mask = np.zeros(image.shape, dtype=np.uint8)    \n",
        "        # # masks = np.zeros(mask_shape, dtype = np.uint8)  \n",
        "        image = Image.fromarray(image)  # cv to PIL\n",
        "        # # 굳이 3채널 정보가 필요하지 않다면, (H, W) 만 받아도, instance 공간 할당은 이미 해놓음\n",
        "        # image = torchvision.transforms(image)    # [C, H, W] \n",
        "        # # PIL\n",
        "        # image = Image.open(image_path).convert(\"RGB\")\n",
        "        # # image = np.asarray(image)\n",
        "        # mask = np.zeros(image.shape, dtype=np.uint8)\n",
        "        \n",
        "        annot_path = self.annots[idx]\n",
        "        if self.mode == \"train\":\n",
        "            # # train인 경우에만 target['masks'] 처리할 함수가 들어가야 함.\n",
        "            # mask_shape, target = self.json2annots(annot_path, idx)\n",
        "            mask, target = self.json2annots(annot_path, idx, mask=mask)\n",
        "        elif self.mode != \"train\":\n",
        "            target = self.json2annots(annot_path, idx)\n",
        "        # target : dict\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            try:\n",
        "                data = self.transforms(img, target)\n",
        "                return data\n",
        "            except:\n",
        "                if self.transforms is not None:\n",
        "                    img = self.transforms(img)\n",
        "                elif self.target_transforms is not None:\n",
        "                    target = self.target_transforms(target)\n",
        "                return img, target\n",
        "        else:\n",
        "            # target_transform만 따로 들어오는 경우는 고려하지 않았음.\n",
        "            img = self.preprocess(image)\n",
        "            return img, target\n",
        "\n",
        "    def baseInfos(self):\n",
        "        baseinfos = {\"label\" : [], \"metainfo_id\" : [], \"feature\" : [], \"image_path\" : [], \"annot_path\": []}\n",
        "        \n",
        "        bpath = os.path.join(self.root, self.mode)\n",
        "        bdirs = sorted(os.listdir(bpath))   # image, annotation(s)\n",
        "        \n",
        "        for bdir in tqdm(bdirs):\n",
        "            for dirs in sorted(os.listdir(os.path.join(bpath, bdir))):\n",
        "                dpath = os.path.join(bpath, bdir, dirs)\n",
        "                \n",
        "                if bdir.lower()=='image':\n",
        "                    paths = sorted(glob(dpath + \"/*.jpg\"))\n",
        "                    baseinfos['image_path'].extend(paths)\n",
        "                    fnames = [os.path.basename(fname) for fname in paths]\n",
        "                    labels = list(map(lambda x: (x.split('_')[0]), fnames))\n",
        "                    baseinfos['label'].extend(labels)\n",
        "                    metaIds = list(map(lambda x: int(x.split('_')[1]), fnames))\n",
        "                    baseinfos['metainfo_id'].extend(metaIds)\n",
        "                    feats = list(map(lambda x: int(x.split('_')[-1][:-4]), fnames))\n",
        "                    baseinfos['feature'].extend(feats)\n",
        "                else:\n",
        "                    paths = sorted(glob(dpath + \"/*.json\"))\n",
        "                    baseinfos['annot_path'].extend(paths)\n",
        "        return baseinfos\n",
        "\n",
        "    def preprocess(self, img):\n",
        "        image = img\n",
        "        import torchvision.transforms as T\n",
        "        m, s = np.mean(image, axis = (0, 1)), np.std(image, axis = (0, 1))        \n",
        "        if self.mode == 'train':\n",
        "            transform = T.Compose([\n",
        "                                   T.ToTensor(),\n",
        "                                   T.Normalize(mean = m, std = s),\n",
        "            ])\n",
        "            image = transform(image)\n",
        "        else:\n",
        "            transform = T.Compose([\n",
        "                                   T.Resize(256),\n",
        "                                   T.ToTensor(),\n",
        "                                   T.Normalize(mean = m, std = s),\n",
        "            ])\n",
        "            image = transform(image)\n",
        "        return image\n",
        "    \n",
        "    def json2annots(self, annot_path, idx, mask=None):\n",
        "        import cv2 as cv\n",
        "        with open(annot_path, 'r') as f:\n",
        "            annot = json.loads(f.read())\n",
        "\n",
        "        n_objects = len(annot['annotations'])\n",
        "        W, H = int(annot['images'][0]['width']), int(annot['images'][0]['height'])\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            # target = {\"boxes\" : [], \"labels\" : [], \"masks\" : [np.zeros((W, H), dtype = np.uint8)], \"image_id\" : [], \"area\" : [], \"iscrowd\" : []}\n",
        "            target = {\"boxes\" : [], \"labels\" : [], \"masks\" : [], \"image_id\" : [], \"area\" : [], \"iscrowd\" : []}\n",
        "\n",
        "            # bbox ground bbox\n",
        "            gxmin, gymin, gxmax, gymax = 0, 0, 0, 0\n",
        "            for i in range(n_objects):\n",
        "                bbox = annot['annotations'][i]['bbox']\n",
        "                xmin, ymin, width, height = bbox[0],bbox[1],bbox[2],bbox[3]\n",
        "                xmax, ymax = xmin + width, ymin + height\n",
        "                target['boxes'].append([xmin, ymin, xmax, ymax])\n",
        "                # ########## just-in-case(ground_bbox) ##########\n",
        "                # gxin = xmin if xmin > gxmin else gxmin\n",
        "                # gymin = ymin if ymin > gymin else gymin\n",
        "                # gmax = xmax if xmax > gxmax else gxmax\n",
        "                # gmax = ymax if ymax > gymax else gymax\n",
        "                # target['boxes'].append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "                label = annot['annotations'][i]['category_id']\n",
        "                # torch.ones로 하지 않은 이유는 클래스 정보가 들어가야된다고 판단했기 때문\n",
        "                target['labels'].append([label])\n",
        "\n",
        "                # try:\n",
        "                #     assert mask!=None\n",
        "                masks = mask.copy() # (H, W, C)\n",
        "                pts = np.array(annot['annotations'][i]['segmentation'], dtype = np.uint8).reshape(-1, 2)    # (num_of_points,2)\n",
        "                # org:[C, H, W] >> [H, W, C] >> [N+1, H, W, C] >> [N, H, W]\n",
        "                pts = np.stack([pts, pts, pts]).astype(int) # (C, num_of_points. 2)\n",
        "                # mask = \n",
        "                cv.fillPoly(masks, pts, (255, 255, 255))    # (H, W, C)\n",
        "\n",
        "                # segmentation = annot['annotations'][i]['segmentation']\n",
        "                # mask = instanceMask(mask=self.masks, segmentation=segmentation)\n",
        "                # mask = self.createMask(annot['annotations'][i]['segmentation'])\n",
        "                instance = cv.cvtColor(mask, cv.COLOR_RGB2GRAY) # (W, H):instance mase\n",
        "\n",
        "                target['masks'].append(instance)\n",
        "\n",
        "                # except:\n",
        "                    # mask 처리 전, 공간 할당\n",
        "                    # target['masks'].append(np.zeros((W, H), dtype=np.uint8))\n",
        "\n",
        "                area = torch.tensor(annot['annotations'][i]['area'], dtype = torch.float32)\n",
        "                target['area'].append([area])\n",
        "\n",
        "                iscrowd = torch.tensor(annot['annotations'][i]['iscrowd'], dtype = torch.int64)\n",
        "                target['iscrowd'].append([iscrowd])\n",
        "                # ignore = torch.tensor(annot['annotations'][i]['ignore'], dtype = torch.int64)\n",
        "                # target['ignore'].append([ignore])\n",
        "\n",
        "            ########################################################## instance id, 필요 시 주석해제 ##########################################################    \n",
        "            # segmentation에 DataLoader 내에서 어떻게 선언되어 있는지 확인해야 함\n",
        "            # target['id'] = torch.stack([torch.tensor([i+1]) for i in range(n_objects)]) # shape : (3, 1)\n",
        "            # ValueError: Expected target boxes to be a tensorof shape [N, 4], got torch.Size([1, 3, 4]).\n",
        "            ########################################################## type은 맞으나, shape이 맞는지 확신이 없는 부분 ##########################################################\n",
        "            # torch.Size([3, 2048, 2048])\n",
        "            # target['boxes'] = torch.as_tensor(target['boxes'], dtype = torch.float32)   \n",
        "            # shape : (3, 4)\n",
        "            target['boxes'] = torch.stack([torch.tensor(bbox, dtype = torch.float32) for bbox in target['boxes']])\n",
        "\n",
        "            # shape : torch.Size([1, 3, 1])\n",
        "            target['labels'] = torch.as_tensor((target['labels'], ), dtype = torch.int64).squeeze()\n",
        "            \n",
        "            # shape : torch.Size([1, 4, 2048, 2048])\n",
        "            # target['masks'] = torch.as_tensor(target['masks'], dtype = torch.uint8) # (2, H, W) : (C, H, W) >> detection?\n",
        "            target['masks'] = torch.stack([torch.tensor(mask, dtype = torch.uint8) for mask in target['masks']])  # [3, 2048, 2048] : (num_of_instance, H, W) >> segmentation?\n",
        "            # mssk 처리 전, 공간 할당\n",
        "\n",
        "            ########################################################## below ~~ torch.Size([3, 1]) : 각각의 shape도 type도 맞는 것 같음 ##########################################################\n",
        "            # image_path[index] -> 이미지 자체의 아이디\n",
        "            target['image_id'] = torch.stack([torch.tensor([idx]) for i in range(n_objects)])   # shape : (3, 1)\n",
        "            target['area'] = torch.as_tensor(target['area'], dtype = torch.float32) # shape : (1, 3) >> (3, 1)\n",
        "            target['iscrowd'] = torch.as_tensor(target['iscrowd'], dtype = torch.int64)\n",
        "            # target['ignore'] = torch.as_tensor(target['ignore'], dtype = torch.int64)\n",
        "            return target['masks'], target\n",
        "\n",
        "        else:\n",
        "            target = {}\n",
        "            try:\n",
        "                target['image_id'] = torch.stack([torch.tensor([idx]) for i in range(n_objects)], dtype = torch.int64)\n",
        "            except:\n",
        "                target['image_id'] = torch.tensor([idx], dtype=torch.int)\n",
        "            return target\n",
        "        # return (n_objects, W, H), target\n",
        "\n",
        "    # def createMask(self, segmentation=None):\n",
        "    #     # if self.pipe != \"detection\":\n",
        "    #     # elif self.pipi != \"detection\":\n",
        "    #     #     img, background = self.imageNmask(image_path, mask_shape)\n",
        "    #     # bbox\n",
        "    #     # segmentation\n",
        "    #     background = self.masks\n",
        "    #     pts_x, pts_y = [], []\n",
        "    #     for i in range(len(segmentation)):\n",
        "    #         pts_x.append(segmentation[i]) if i%2 == 0 else pts_y.append(segmentation[i])\n",
        "    #     polygon_xy = np.array([(x, y) for (x, y) in zip(pts_x, pts_y)])\n",
        "    #     cv2.fillPoly(background, np.uint([polygon_xy]), i)\n",
        "    #     return background\n",
        " \n",
        "    def _labels2category(self, label):\n",
        "        category = {1 : \"PET\", 2 : \"PS\", 3 : \"PP\", 4 : \"PE\"}\n",
        "        return category(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    # ########## just-in-case ##########\n",
        "    # # when we need more edas\n",
        "    # def additional_infos(self):\n",
        "    #     with open(self.annots[0], 'r') as f:\n",
        "    #         annot = json.loads(f.read())\n",
        "    #     metainfo = annot['metainfo']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV2HZ7sn_ZOV",
        "outputId": "df9a4a6a-2dd2-484a-decd-0f571164d7b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CaliberDataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smHx_S4Km28-"
      },
      "source": [
        "## CustomDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOLenWki-BzB"
      },
      "source": [
        "image segmentation을 위해선 target[boxes, labels, masks] 필수\n",
        "- 통상 \"image_id\", 마스크가 속한 이미지 id\n",
        "- \"area\", box 면적, pred box, act box IoU 구할 때 필요\n",
        "- \"iscrowd\", 작은 물체를 하나의 군집으로 박스처리하여 레이블링 했는지에 관한 여부, 물체가 숨어져있거나, 가려진 경우 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBVXL-mxBm1F"
      },
      "source": [
        "# pip show opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjLgiYsSBxIF"
      },
      "source": [
        "# pip install -U opencv-python==4.5.3.56"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv3Qb3eCdVAy"
      },
      "source": [
        "# mm = np.zeros((128, 128, 3), dtype=np.uint8)\n",
        "# print(mm.shape, mm.ndim)\n",
        "\n",
        "# nn = cv.cvtColor(mm[:,:,:], cv.COLOR_RGB2GRAY)\n",
        "\n",
        "# print(nn.shape, nn.ndim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# 원래 데이터 intance마다\n",
        "def random_colour_masks(image):\n",
        "    colours = [[0, 255, 0],[0, 0, 255],[255, 0, 0],[0, 255, 255],[255, 255, 0],[255, 0, 255],[80, 70, 180],[250, 80, 190],[245, 145, 50],[70, 150, 250],[50, 190, 190]]\n",
        "    r = np.zeros_like(image).astype(np.uint8)\n",
        "    g = np.zeros_like(image).astype(np.uint8)\n",
        "    b = np.zeros_like(image).astype(np.uint8)\n",
        "    r[image == 1], g[image == 1], b[image == 1] = colours[random.randrange(0,10)]\n",
        "    coloured_mask = np.stack([r, g, b], axis=2)\n",
        "    return coloured_mask \n",
        "\n",
        "def instanceMask(mask, segmentation):\n",
        "    import cv2 as cv\n",
        "    mask = mask.copy()\n",
        "    pts = np.array(segmentation, dtype = np.uint8).reshape(-1, 2)\n",
        "\n",
        "    pts = np.stack([pts, pts, pts])\n",
        "    cv.fillPoly(mask, pts, color=(255, 255, 255))\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root, transforms = None, target_transforms = None, mode = 'train'):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.target_transforms = target_transforms\n",
        "        self.mode = mode.lower()\n",
        "        self.infos = self.baseInfos()\n",
        "        self.imgs, self.annots = self.infos['image_path'], self.infos['annot_path']\n",
        "        # if self.mode == 'train':\n",
        "        #     self.imgs, self.masks = blahblah\n",
        "        self.masks = None\n",
        "\n",
        "    def __getitem__(self, idx=None):\n",
        "        '''return tuple(image, target)'''\n",
        "        image_path = self.imgs[idx]\n",
        "        # # mask 생성 함수보고 고쳐야 할 듯\n",
        "        image = cv.imread(image_path)\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        # C, H, W ==  [H, W, C] >> [N+1, H, W, C] >> [N, H, W]\n",
        "        mask = np.zeros(image.shape, dtype=np.uint8)    \n",
        "        # # masks = np.zeros(mask_shape, dtype = np.uint8)  \n",
        "        image = Image.fromarray(image)  # cv to PIL\n",
        "        # # 굳이 3채널 정보가 필요하지 않다면, (H, W) 만 받아도, instance 공간 할당은 이미 해놓음\n",
        "        # image = torchvision.transforms(image)    # [C, H, W] \n",
        "        # # PIL\n",
        "        # image = Image.open(image_path).convert(\"RGB\")\n",
        "        # # image = np.asarray(image)\n",
        "        # mask = np.zeros(image.shape, dtype=np.uint8)\n",
        "        \n",
        "        annot_path = self.annots[idx]\n",
        "        if self.mode == \"train\":\n",
        "            # # train인 경우에만 target['masks'] 처리할 함수가 들어가야 함.\n",
        "            # mask_shape, target = self.json2annots(annot_path, idx)\n",
        "            mask, target = self.json2annots(annot_path, idx, mask=mask)\n",
        "        elif self.mode != \"train\":\n",
        "            target = self.json2annots(annot_path, idx)\n",
        "        # target : dict\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            try:\n",
        "                data = self.transforms(img, target)\n",
        "                return data\n",
        "            except:\n",
        "                if self.transforms is not None:\n",
        "                    img = self.transforms(img)\n",
        "                elif self.target_transforms is not None:\n",
        "                    target = self.target_transforms(target)\n",
        "                return img, target\n",
        "        else:\n",
        "            # target_transform만 따로 들어오는 경우는 고려하지 않았음.\n",
        "            img = self.preprocess(image)\n",
        "            return img, target\n",
        "\n",
        "    def baseInfos(self):\n",
        "        baseinfos = {\"label\" : [], \"metainfo_id\" : [], \"feature\" : [], \"image_path\" : [], \"annot_path\": []}\n",
        "        \n",
        "        if self.mode == \"val\":\n",
        "          bpath = os.path.join(self.root, \"train\")\n",
        "        else:\n",
        "          bpath = os.path.join(self.root, self.mode)\n",
        "        bdirs = sorted(os.listdir(bpath))   # image, annotation(s)\n",
        "        \n",
        "        for bdir in tqdm(bdirs):\n",
        "            for dirs in sorted(os.listdir(os.path.join(bpath, bdir))):\n",
        "                dpath = os.path.join(bpath, bdir, dirs)\n",
        "                \n",
        "                if bdir.lower()=='image':\n",
        "                    paths = sorted(glob(dpath + \"/*.jpg\"))\n",
        "                    baseinfos['image_path'].extend(paths)\n",
        "                    fnames = [os.path.basename(fname) for fname in paths]\n",
        "                    labels = list(map(lambda x: (x.split('_')[0]), fnames))\n",
        "                    baseinfos['label'].extend(labels)\n",
        "                    metaIds = list(map(lambda x: int(x.split('_')[1]), fnames))\n",
        "                    baseinfos['metainfo_id'].extend(metaIds)\n",
        "                    feats = list(map(lambda x: int(x.split('_')[-1][:-4]), fnames))\n",
        "                    baseinfos['feature'].extend(feats)\n",
        "                else:\n",
        "                    paths = sorted(glob(dpath + \"/*.json\"))\n",
        "                    baseinfos['annot_path'].extend(paths)\n",
        "        return baseinfos\n",
        "\n",
        "    def preprocess(self, img):\n",
        "        image = img\n",
        "        import torchvision.transforms as T\n",
        "        m, s = np.mean(image, axis = (0, 1)), np.std(image, axis = (0, 1))        \n",
        "        if self.mode == 'train':\n",
        "            transform = T.Compose([\n",
        "                                   T.ToTensor(),\n",
        "                                   T.Normalize(mean = m, std = s),\n",
        "            ])\n",
        "            image = transform(image)\n",
        "        else:\n",
        "            transform = T.Compose([\n",
        "                                   T.Resize(256),\n",
        "                                   T.ToTensor(),\n",
        "                                   T.Normalize(mean = m, std = s),\n",
        "            ])\n",
        "            image = transform(image)\n",
        "        return image\n",
        "    \n",
        "    def json2annots(self, annot_path, idx, mask=None):\n",
        "        import cv2 as cv\n",
        "        with open(annot_path, 'r') as f:\n",
        "            annot = json.loads(f.read())\n",
        "\n",
        "        n_objects = len(annot['annotations'])\n",
        "        W, H = int(annot['images'][0]['width']), int(annot['images'][0]['height'])\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            # target = {\"boxes\" : [], \"labels\" : [], \"masks\" : [np.zeros((W, H), dtype = np.uint8)], \"image_id\" : [], \"area\" : [], \"iscrowd\" : []}\n",
        "            target = {\"boxes\" : [], \"labels\" : [], \"masks\" : [], \"image_id\" : [], \"area\" : [], \"iscrowd\" : []}\n",
        "\n",
        "            # bbox ground bbox\n",
        "            gxmin, gymin, gxmax, gymax = 0, 0, 0, 0\n",
        "            for i in range(n_objects):\n",
        "                bbox = annot['annotations'][i]['bbox']\n",
        "                xmin, ymin, width, height = bbox[0],bbox[1],bbox[2],bbox[3]\n",
        "                xmax, ymax = xmin + width, ymin + height\n",
        "                target['boxes'].append([xmin, ymin, xmax, ymax])\n",
        "                # ########## just-in-case(ground_bbox) ##########\n",
        "                # gxin = xmin if xmin > gxmin else gxmin\n",
        "                # gymin = ymin if ymin > gymin else gymin\n",
        "                # gmax = xmax if xmax > gxmax else gxmax\n",
        "                # gmax = ymax if ymax > gymax else gymax\n",
        "                # target['boxes'].append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "                label = annot['annotations'][i]['category_id']\n",
        "                # torch.ones로 하지 않은 이유는 클래스 정보가 들어가야된다고 판단했기 때문\n",
        "                target['labels'].append([label])\n",
        "\n",
        "                # try:\n",
        "                #     assert mask!=None\n",
        "                masks = mask.copy() # (H, W, C)\n",
        "                pts = np.array(annot['annotations'][i]['segmentation'], dtype = np.uint8).reshape(-1, 2)    # (num_of_points,2)\n",
        "                # org:[C, H, W] >> [H, W, C] >> [N+1, H, W, C] >> [N, H, W]\n",
        "                pts = np.stack([pts, pts, pts]).astype(int) # (C, num_of_points. 2)\n",
        "                # mask = \n",
        "                cv.fillPoly(masks, pts, (255, 255, 255))    # (H, W, C)\n",
        "\n",
        "                # segmentation = annot['annotations'][i]['segmentation']\n",
        "                # mask = instanceMask(mask=self.masks, segmentation=segmentation)\n",
        "                # mask = self.createMask(annot['annotations'][i]['segmentation'])\n",
        "                instance = cv.cvtColor(mask, cv.COLOR_RGB2GRAY) # (W, H):instance mase\n",
        "\n",
        "                target['masks'].append(instance)\n",
        "\n",
        "                # except:\n",
        "                    # mask 처리 전, 공간 할당\n",
        "                    # target['masks'].append(np.zeros((W, H), dtype=np.uint8))\n",
        "\n",
        "                area = torch.tensor(annot['annotations'][i]['area'], dtype = torch.float32)\n",
        "                target['area'].append([area])\n",
        "\n",
        "                iscrowd = torch.tensor(annot['annotations'][i]['iscrowd'], dtype = torch.int64)\n",
        "                target['iscrowd'].append([iscrowd])\n",
        "                # ignore = torch.tensor(annot['annotations'][i]['ignore'], dtype = torch.int64)\n",
        "                # target['ignore'].append([ignore])\n",
        "\n",
        "            ########################################################## instance id, 필요 시 주석해제 ##########################################################    \n",
        "            # segmentation에 DataLoader 내에서 어떻게 선언되어 있는지 확인해야 함\n",
        "            # target['id'] = torch.stack([torch.tensor([i+1]) for i in range(n_objects)]) # shape : (3, 1)\n",
        "            # ValueError: Expected target boxes to be a tensorof shape [N, 4], got torch.Size([1, 3, 4]).\n",
        "            ########################################################## type은 맞으나, shape이 맞는지 확신이 없는 부분 ##########################################################\n",
        "            # torch.Size([3, 2048, 2048])\n",
        "            # target['boxes'] = torch.as_tensor(target['boxes'], dtype = torch.float32)   \n",
        "            # shape : (3, 4)\n",
        "            target['boxes'] = torch.stack([torch.tensor(bbox, dtype = torch.float32) for bbox in target['boxes']])\n",
        "\n",
        "            # shape : torch.Size([1, 3, 1])\n",
        "            target['labels'] = torch.as_tensor((target['labels'], ), dtype = torch.int64).squeeze()\n",
        "            \n",
        "            # shape : torch.Size([1, 4, 2048, 2048])\n",
        "            # target['masks'] = torch.as_tensor(target['masks'], dtype = torch.uint8) # (2, H, W) : (C, H, W) >> detection?\n",
        "            target['masks'] = torch.stack([torch.tensor(mask, dtype = torch.uint8) for mask in target['masks']])  # [3, 2048, 2048] : (num_of_instance, H, W) >> segmentation?\n",
        "            # mssk 처리 전, 공간 할당\n",
        "\n",
        "            ########################################################## below ~~ torch.Size([3, 1]) : 각각의 shape도 type도 맞는 것 같음 ##########################################################\n",
        "            # image_path[index] -> 이미지 자체의 아이디\n",
        "            target['image_id'] = torch.stack([torch.tensor([idx]) for i in range(n_objects)])   # shape : (3, 1)\n",
        "            target['area'] = torch.as_tensor(target['area'], dtype = torch.float32) # shape : (1, 3) >> (3, 1)\n",
        "            target['iscrowd'] = torch.as_tensor(target['iscrowd'], dtype = torch.int64)\n",
        "            # target['ignore'] = torch.as_tensor(target['ignore'], dtype = torch.int64)\n",
        "            return target['masks'], target\n",
        "\n",
        "        else:\n",
        "            target = {}\n",
        "            try:\n",
        "                target['image_id'] = torch.stack([torch.tensor([idx]) for i in range(n_objects)], dtype = torch.int64)\n",
        "            except:\n",
        "                target['image_id'] = torch.tensor([idx], dtype=torch.int)\n",
        "            return target\n",
        "        # return (n_objects, W, H), target\n",
        "\n",
        "    # def createMask(self, segmentation=None):\n",
        "    #     # if self.pipe != \"detection\":\n",
        "    #     # elif self.pipi != \"detection\":\n",
        "    #     #     img, background = self.imageNmask(image_path, mask_shape)\n",
        "    #     # bbox\n",
        "    #     # segmentation\n",
        "    #     background = self.masks\n",
        "    #     pts_x, pts_y = [], []\n",
        "    #     for i in range(len(segmentation)):\n",
        "    #         pts_x.append(segmentation[i]) if i%2 == 0 else pts_y.append(segmentation[i])\n",
        "    #     polygon_xy = np.array([(x, y) for (x, y) in zip(pts_x, pts_y)])\n",
        "    #     cv2.fillPoly(background, np.uint([polygon_xy]), i)\n",
        "    #     return background\n",
        " \n",
        "    def _labels2category(self, label):\n",
        "        category = {1 : \"PET\", 2 : \"PS\", 3 : \"PP\", 4 : \"PE\"}\n",
        "        return category(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    # ########## just-in-case ##########\n",
        "    # # when we need more edas\n",
        "    # def additional_infos(self):\n",
        "    #     with open(self.annots[0], 'r') as f:\n",
        "    #         annot = json.loads(f.read())\n",
        "    #     metainfo = annot['metainfo']"
      ],
      "metadata": {
        "id": "RWetp2dKQWO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674,
          "referenced_widgets": [
            "98f358c10a29418482622c1c24cbe8ab",
            "d1dbbcd24c514d8aa0a002963442b6cd",
            "570706732098418d853c20d890ef4e1f",
            "ab64fcf2b1eb4bbc9016a3376f71569f",
            "629895d515ec4857a9de4571dd8f798e",
            "0432fc53333c4094ac1876fba9e5397a",
            "6ff2368bdb6946448bf576882df7fcc0",
            "f0b5683ca2614c3c903100a06db3e2cb",
            "4d7f9ffa5567495ca182c5fb8b1b1e70",
            "7fc23311d3f849d48314152eefebe5c6",
            "a5665a54e2aa4d12bcb1452746f16b55"
          ]
        },
        "id": "G6H7D2AYrCkI",
        "outputId": "c9fd0d3b-a9ec-4d33-b614-3e63b096a79e"
      },
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "dataset = CustomDataset(PATH)\n",
        "\n",
        "idx = random.randint(0, dataset.__len__())\n",
        "\n",
        "print(f\"{idx}번째 train 이미지\")\n",
        "\n",
        "# C, W, H, N\n",
        "# \n",
        "# num_classes, W, H, Batch(num_instance + 1) : mask\n",
        "print(f\"\\t 이미지 shape : {dataset[idx][0].shape}\\n\\t 이미지 type : {dataset[idx][0].type()}\")\n",
        "for k in list(dataset[idx][1].keys()):\n",
        "     print(f\"\\t\\tdict_keys == '{k}' :  \\n\\t\\t\\tshape : {dataset[idx][1][k].shape}\\n\\t\\t\\ttype : {dataset[idx][1][k].type()}\")\n",
        "     if k is not \"masks\":\n",
        "         print(f\"\\t\\t\\t{dataset[idx][1][k]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98f358c10a29418482622c1c24cbe8ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/160M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:20<00:00, 10.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1882번째 train 이미지\n",
            "\t 이미지 shape : torch.Size([3, 2024, 2024])\n",
            "\t 이미지 type : torch.FloatTensor\n",
            "\t\tdict_keys == 'boxes' :  \n",
            "\t\t\tshape : torch.Size([3, 4])\n",
            "\t\t\ttype : torch.FloatTensor\n",
            "\t\t\ttensor([[ 521.,  244.,  758.,  464.],\n",
            "        [1065.,  722., 1281.,  947.],\n",
            "        [ 369.,  565.,  966., 1232.]])\n",
            "\t\tdict_keys == 'labels' :  \n",
            "\t\t\tshape : torch.Size([3])\n",
            "\t\t\ttype : torch.LongTensor\n",
            "\t\t\ttensor([1, 1, 1])\n",
            "\t\tdict_keys == 'masks' :  \n",
            "\t\t\tshape : torch.Size([3, 2024, 2024])\n",
            "\t\t\ttype : torch.ByteTensor\n",
            "\t\tdict_keys == 'image_id' :  \n",
            "\t\t\tshape : torch.Size([3, 1])\n",
            "\t\t\ttype : torch.LongTensor\n",
            "\t\t\ttensor([[1882],\n",
            "        [1882],\n",
            "        [1882]])\n",
            "\t\tdict_keys == 'area' :  \n",
            "\t\t\tshape : torch.Size([3, 1])\n",
            "\t\t\ttype : torch.FloatTensor\n",
            "\t\t\ttensor([[ 40281.5000],\n",
            "        [ 39518.0000],\n",
            "        [348839.0000]])\n",
            "\t\tdict_keys == 'iscrowd' :  \n",
            "\t\t\tshape : torch.Size([3, 1])\n",
            "\t\t\ttype : torch.LongTensor\n",
            "\t\t\ttensor([[0],\n",
            "        [0],\n",
            "        [0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoGFZFStoV3o"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvAeApQ70QIU",
        "outputId": "3aaf7d84-012e-4952-c4d4-fc75eb597d17"
      },
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "dataset = CustomDataset(PATH)\n",
        "\n",
        "idx = random.randint(0, dataset.__len__())\n",
        "\n",
        "print(f\"{idx}번째 train 이미지\")\n",
        "\n",
        "# C, W, H, N\n",
        "# \n",
        "# num_classes, W, H, Batch(num_instance + 1) : mask\n",
        "print(f\"\\t 이미지 shape : {dataset[idx][0].shape}\\n\\t 이미지 type : {dataset[idx][0].type()}\")\n",
        "for k in list(dataset[idx][1].keys()):\n",
        "     print(f\"\\t\\tdict_keys == '{k}' :  \\n\\t\\t\\tshape : {dataset[idx][1][k].shape}\\n\\t\\t\\ttype : {dataset[idx][1][k].type()}\")\n",
        "     if k is not \"masks\":\n",
        "         print(f\"\\t\\t\\t{dataset[idx][1][k]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 12.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2142번째 train 이미지\n",
            "\t 이미지 shape : torch.Size([3, 2048, 2048])\n",
            "\t 이미지 type : torch.FloatTensor\n",
            "\t\tdict_keys == 'boxes' :  \n",
            "\t\t\tshape : torch.Size([3, 4])\n",
            "\t\t\ttype : torch.FloatTensor\n",
            "\t\t\ttensor([[ 824.,  457., 1204.,  852.],\n",
            "        [ 394.,  979.,  778., 1364.],\n",
            "        [1009., 1128., 1354., 1469.]])\n",
            "\t\tdict_keys == 'labels' :  \n",
            "\t\t\tshape : torch.Size([3])\n",
            "\t\t\ttype : torch.LongTensor\n",
            "\t\t\ttensor([3, 3, 3])\n",
            "\t\tdict_keys == 'masks' :  \n",
            "\t\t\tshape : torch.Size([3, 2048, 2048])\n",
            "\t\t\ttype : torch.ByteTensor\n",
            "\t\tdict_keys == 'image_id' :  \n",
            "\t\t\tshape : torch.Size([3, 1])\n",
            "\t\t\ttype : torch.LongTensor\n",
            "\t\t\ttensor([[2142],\n",
            "        [2142],\n",
            "        [2142]])\n",
            "\t\tdict_keys == 'area' :  \n",
            "\t\t\tshape : torch.Size([3, 1])\n",
            "\t\t\ttype : torch.FloatTensor\n",
            "\t\t\ttensor([[117983.5000],\n",
            "        [116196.5000],\n",
            "        [ 91739.0000]])\n",
            "\t\tdict_keys == 'iscrowd' :  \n",
            "\t\t\tshape : torch.Size([3, 1])\n",
            "\t\t\ttype : torch.LongTensor\n",
            "\t\t\ttensor([[0],\n",
            "        [0],\n",
            "        [0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfQJOcqfbrXQ",
        "outputId": "8e862a2e-3960-432f-e9ef-fa538a3efd37"
      },
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=utils.collate_fn)\n",
        "\n",
        "# train\n",
        "images,targets = next(iter(data_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "output = model(images,targets)   # Returns losses and detections\n",
        "\n",
        "# inference\n",
        "model.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictions = model(x)           # Returns predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nskPrwrxoYqE",
        "outputId": "77ec70b9-d882-40f2-8f0c-bd435f944bd6"
      },
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "dataset = CustomDataset(PATH)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=utils.collate_fn)\n",
        "\n",
        "# train\n",
        "images,targets = next(iter(data_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "output = model(images,targets)   # Returns losses and detections\n",
        "\n",
        "# inference\n",
        "model.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictions = model(x)           # Returns predictions\n",
        "\n",
        "# /usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
        "#   return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 13.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIErSrcwdHhp",
        "outputId": "0a5185ba-a4fc-4430-9dfe-7b4eaac4e05a"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>),\n",
              "  'labels': tensor([], dtype=torch.int64),\n",
              "  'scores': tensor([], grad_fn=<IndexBackward0>)},\n",
              " {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>),\n",
              "  'labels': tensor([], dtype=torch.int64),\n",
              "  'scores': tensor([], grad_fn=<IndexBackward0>)}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "WWkdm6fWymSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(T.ToTensor())\n",
        "    if train:\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)\n",
        "\n",
        "def quick_check(dataset, idx):\n",
        "    print(f\"{idx}번째 {dataset.mode} 이미지\")\n",
        "    print(f\"\\t 이미지 shape : {dataset[idx][0].shape}\\n\\t 이미지 type : {dataset[idx][0].type()}\")\n",
        "    for k in list(dataset[idx][1].keys()):\n",
        "        print(f\"\\t\\tdict_keys == '{k}' :  \\n\\t\\t\\tshape : {dataset[idx][1][k].shape}\\n\\t\\t\\ttype : {dataset[idx][1][k].type()}\")\n",
        "        if k is not \"masks\":\n",
        "            print(f\"\\t\\t\\t{dataset[idx][1][k]}\\n\\n\")\n",
        "\n",
        "def uni_inference(precision, idx):\n",
        "    print(f\"inference no.{idx} : \")\n",
        "    for k in list(precision[0].keys()):\n",
        "        print(f\"\\t{k} : \\n\\t\\t shape : {precision[0][k].shape}\\n\")\n",
        "\n",
        "# fastrcnn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# unet ; torch.hub\n",
        "\n",
        "# fasterrcnn\n",
        "import torchvision\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "# %%writefile ./CaliberDetector.py    # customize 끝내고 run\n",
        "\n",
        "# detection\n",
        "from collections import OrderedDict\n",
        "from torch import nn\n",
        "from torchvision.ops import MultiScaleRoIAlign\n",
        "from torchvision._internally_replaced_utils import load_state_dict_from_url\n",
        "from torchvision.models.detection._utils import overwrite_eps\n",
        "from torchvision.models.detection.faster_rcnn import FasterRCNN\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone, _validate_trainable_layers"
      ],
      "metadata": {
        "id": "eAe1JgUiynkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        " \n",
        "# num_classes == custom data num_classes\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    # load an instance segmentation model pre-trained on COCO,,,resnet50(backbone), fpn(head)\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        " \n",
        "    # get the number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        " \n",
        "    # now get the number of input features for the mask classifier\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    # and replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
        "                                                       hidden_layer,\n",
        "                                                       num_classes)\n",
        " \n",
        "    return model"
      ],
      "metadata": {
        "id": "HnYOLDCTyt3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_factor = False # 0.5\n",
        "\n",
        "# Normalize to resnet mean and std if True.\n",
        "NORMALIZE = False\n",
        "RESNET_MEAN = (0.485, 0.456, 0.406)\n",
        "RESNET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "# No changes tried with the optimizer yet.\n",
        "MOMENTUM = 0.9\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.0005\n",
        "\n",
        "# Changes the confidence required for a pixel to be kept for a mask. \n",
        "# Only used 0.5 till now.\n",
        "# MASK_THRESHOLD = 0.5\n",
        "# MIN_SCORE = 0.5\n",
        "# cell type specific thresholds\n",
        "cell_type_dict = {\"astro\": 1, \"cort\": 2, \"shsy5y\": 3}\n",
        "mask_threshold_dict = {1: 0.55, 2: 0.75, 3:  0.6}\n",
        "min_score_dict = {1: 0.55, 2: 0.75, 3: 0.5}\n",
        "\n",
        "# Use a StepLR scheduler if True. \n",
        "USE_SCHEDULER = False\n",
        "\n",
        "PCT_IMAGES_VALIDATION = 0.075\n",
        "\n",
        "BOX_DETECTIONS_PER_IMG = 540"
      ],
      "metadata": {
        "id": "P7iD3_Ay0JFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch\n",
        "model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
        "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "PATH = os.path.join(ROOT, \"MyDrive/Task/plastic-segmentation/Data\")\n",
        "train = CustomDataset(root =PATH)\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    train, batch_size=5, shuffle=True, num_workers=2,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "# For Training\n",
        "images,targets = next(iter(data_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "\n",
        "output = model(images,targets)   # Returns losses and detections\n",
        "# For inference\n",
        "model.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictions = model(x)\n",
        "\n",
        "def save_general_checkpoint(net, optimizer, NUM_EPOCHS, model_name, purpose, BATCH_SIZE, LOSS):\n",
        "    EPOCH = NUM_EPOCHS\n",
        "    PATH = f\"./{model_name}_{purpose}_{BATCH_SIZE}_{EPOCH}.pt\"\n",
        "    LOSS = 0.4\n",
        "\n",
        "    torch.save({\n",
        "        'epoch':EPOCH,\n",
        "        'model_state_dict':net.state_dict(),\n",
        "        'optimizer_state_dict':optimizer.state_dict(),\n",
        "        'loss':LOSS,\n",
        "        }, PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "7c53883a769e4816bbec01dd380aec83",
            "9721447cc953443bbe82dca4b0b62486",
            "01306ecb380143dd8062f01cbcd41afe",
            "beeb9542f95244de82fef2ed1aef41b9",
            "61575573f8214537868cfe0966507143",
            "2414ce0d4fb34b2bb99eab5f42f2d589",
            "dc012b89b8634277bd617e55a01e870e",
            "bba14996a9b642b4b28e01fe8bbe8fb8",
            "8091108683944bf09d103decb1791615",
            "83d354f4eafc43f589eabd2ab543bee2",
            "bb4e7a56cb164da08248b5bee6b9cfce"
          ]
        },
        "id": "YGFd_XWD0mDA",
        "outputId": "52b0a99c-cae2-4270-9310-9a099feba07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c53883a769e4816bbec01dd380aec83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/74.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 11.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        " \n",
        "# our dataset has two classes only - background and person : 튜토리얼\n",
        "# 4 + 1\n",
        "num_classes = 5\n",
        " \n",
        "# get the model using our helper function\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        " \n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        " \n",
        "# and a learning rate scheduler which decreases the learning rate by\n",
        "# 10x every 3 epochs\n",
        "# what if 10x every 6 epochs or 5 epochs?\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "abea681863294730955d34313bbf79be",
            "66f2acf85c6d465b887964da6471ca20",
            "d30a625ec18d43c7a0c5d0056cd7b0d3",
            "7afdb15959d749db83af85587585a901",
            "634c18ace7be452581c1821c5423df8f",
            "c8806dff22354b3a9ad85be75f76f498",
            "0b640a0dff19492b9eebc2a628877b68",
            "cfa41288d6ac434a88540ab9c87f7427",
            "d183128f7c9e47cba8607d7c3a53a476",
            "b36c1e610c7d47368ffe68e49976e071",
            "5abedc71d23c4cb0adae2bdd6307842a"
          ]
        },
        "id": "imDNymdQ0zFt",
        "outputId": "0db47bee-071e-4eaa-d1ff-668dd85d7542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abea681863294730955d34313bbf79be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/170M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# No changes tried with the optimizer yet.\n",
        "from typing import Any, Callable, cast, Dict, List, Optional, Tuple\n",
        "BATCH_SIZE = 1\n",
        "NUM_EPOCHS = 5\n",
        "MOMENTUM = 0.9\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.0005\n",
        "\n",
        "PATH = os.path.join(ROOT, \"MyDrive/Task/plastic-segmentation/Sample_data\")\n",
        "\n",
        "train_dataset = CustomDataset(root=PATH, mode = 'train')\n",
        "test_dataset = CustomDataset(root=PATH, mode='train')\n",
        "\n",
        "# split the dataset in train and test set\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(train_dataset)).tolist()\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(train_dataset, indices[:-56]) # 224-56:56:56 이 맞는지는 모르겠습니다.\n",
        "test_dataset = torch.utils.data.Subset(test_dataset, indices[-56:])\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "#optimizer = torch.optim.Adam(params, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "# define training and validation data loaders\n",
        "dl_train = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "dl_val = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "n_batches, n_batches_val = len(train_dataset), len(test_dataset)\n",
        "\n",
        "validation_mask_losses = []\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    print(f\"Starting epoch {epoch} of {NUM_EPOCHS}\")\n",
        "\n",
        "    time_start = time.time()\n",
        "    loss_accum = 0.0\n",
        "    loss_mask_accum = 0.0\n",
        "    loss_classifier_accum = 0.0\n",
        "    # for batch_idx, (images, targets) in enumerate(dl_train, 1):\n",
        "    for batch_idx, (images, targets) in enumerate(dl_train):\n",
        "    \n",
        "        # Predict\n",
        "        images = list(image.to(DEVICE) for image in images)\n",
        "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        print(type(loss_dict), len(loss_dict))\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        \n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Logging\n",
        "        loss_mask = loss_dict['loss_mask'].item()\n",
        "        loss_accum += loss.item()\n",
        "        loss_mask_accum += loss_mask\n",
        "        loss_classifier_accum += loss_dict['loss_classifier'].item()\n",
        "        \n",
        "        if batch_idx % 500 == 0:\n",
        "            print(f\"    [Batch {batch_idx:3d} / {n_batches:3d}] Batch train loss: {loss.item():7.3f}. Mask-only loss: {loss_mask:7.3f}.\")\n",
        "                        \n",
        "    if USE_SCHEDULER:\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    # Train losses\n",
        "    train_loss = loss_accum / n_batches\n",
        "    train_loss_mask = loss_mask_accum / n_batches\n",
        "    train_loss_classifier = loss_classifier_accum / n_batches\n",
        "\n",
        "    # Validation\n",
        "    val_loss_accum = 0\n",
        "    val_loss_mask_accum = 0\n",
        "    val_loss_classifier_accum = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, targets) in enumerate(dl_val, 1):\n",
        "            images = list(image.to(DEVICE) for image in images)\n",
        "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            val_loss_dict = model(images, targets)\n",
        "            val_batch_loss = sum(loss for loss in val_loss_dict.values())\n",
        "            val_loss_accum += val_batch_loss.item()\n",
        "            val_loss_mask_accum += val_loss_dict['loss_mask'].item()\n",
        "            val_loss_classifier_accum += val_loss_dict['loss_classifier'].item()\n",
        "\n",
        "            # save_general_checkpoint(model, optimizer, NUM_EPOCHS, f\"iter_{BATCH_SIZE}\", \"seg\", batch_idx, val_loss_accum)\n",
        "\n",
        "    # Validation losses\n",
        "    val_loss = val_loss_accum / n_batches_val\n",
        "    val_loss_mask = val_loss_mask_accum / n_batches_val\n",
        "    val_loss_classifier = val_loss_classifier_accum / n_batches_val\n",
        "    elapsed = time.time() - time_start\n",
        "\n",
        "    validation_mask_losses.append(val_loss_mask)\n",
        "\n",
        "    torch.save(model.state_dict(), f\"pytorch_model-e{epoch}.pth\")\n",
        "    prefix = f\"[Epoch {epoch:2d} / {NUM_EPOCHS:2d}]\"\n",
        "    # print(prefix)\n",
        "    print(f\"{prefix} Train mask-only loss: {train_loss_mask:7.3f}, classifier loss {train_loss_classifier:7.3f}\")\n",
        "    print(f\"{prefix} Val mask-only loss  : {val_loss_mask:7.3f}, classifier loss {val_loss_classifier:7.3f}\")\n",
        "    print(prefix)\n",
        "    print(f\"{prefix} Train loss: {train_loss:7.3f}. Val loss: {val_loss:7.3f} [{elapsed:.0f} secs]\")\n",
        "    # print(prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-XfGG2E03Ln",
        "outputId": "6066cefa-b315-4d41-d1dc-8c86ebd4288c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n",
            "100%|██████████| 2/2 [00:00<00:00, 94.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1 of 5\n",
            "<class 'dict'> 5\n",
            "    [Batch   0 / 168] Batch train loss:   3.450. Mask-only loss:   1.293.\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "[Epoch  1 /  5]\n",
            "[Epoch  1 /  5] Train mask-only loss:   0.019, classifier loss   0.248\n",
            "[Epoch  1 /  5] Val mask-only loss  :   0.001, classifier loss   0.247\n",
            "[Epoch  1 /  5]\n",
            "[Epoch  1 /  5] Train loss:   0.592. Val loss:   0.518 [748 secs]\n",
            "[Epoch  1 /  5]\n",
            "Starting epoch 2 of 5\n",
            "<class 'dict'> 5\n",
            "    [Batch   0 / 168] Batch train loss:   0.307. Mask-only loss:   0.001.\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "[Epoch  2 /  5]\n",
            "[Epoch  2 /  5] Train mask-only loss:   0.000, classifier loss   0.253\n",
            "[Epoch  2 /  5] Val mask-only loss  :   0.000, classifier loss   0.238\n",
            "[Epoch  2 /  5]\n",
            "[Epoch  2 /  5] Train loss:   0.549. Val loss:   0.503 [652 secs]\n",
            "[Epoch  2 /  5]\n",
            "Starting epoch 3 of 5\n",
            "<class 'dict'> 5\n",
            "    [Batch   0 / 168] Batch train loss:   0.639. Mask-only loss:   0.000.\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "[Epoch  3 /  5]\n",
            "[Epoch  3 /  5] Train mask-only loss:   0.000, classifier loss   0.260\n",
            "[Epoch  3 /  5] Val mask-only loss  :   0.000, classifier loss   0.255\n",
            "[Epoch  3 /  5]\n",
            "[Epoch  3 /  5] Train loss:   0.566. Val loss:   0.552 [652 secs]\n",
            "[Epoch  3 /  5]\n",
            "Starting epoch 4 of 5\n",
            "<class 'dict'> 5\n",
            "    [Batch   0 / 168] Batch train loss:   0.460. Mask-only loss:   0.000.\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "[Epoch  4 /  5]\n",
            "[Epoch  4 /  5] Train mask-only loss:   0.000, classifier loss   0.238\n",
            "[Epoch  4 /  5] Val mask-only loss  :   0.000, classifier loss   0.225\n",
            "[Epoch  4 /  5]\n",
            "[Epoch  4 /  5] Train loss:   0.519. Val loss:   0.493 [656 secs]\n",
            "[Epoch  4 /  5]\n",
            "Starting epoch 5 of 5\n",
            "<class 'dict'> 5\n",
            "    [Batch   0 / 168] Batch train loss:   0.741. Mask-only loss:   0.000.\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "<class 'dict'> 5\n",
            "[Epoch  5 /  5]\n",
            "[Epoch  5 /  5] Train mask-only loss:   0.000, classifier loss   0.256\n",
            "[Epoch  5 /  5] Val mask-only loss  :   0.000, classifier loss   0.227\n",
            "[Epoch  5 /  5]\n",
            "[Epoch  5 /  5] Train loss:   0.564. Val loss:   0.508 [658 secs]\n",
            "[Epoch  5 /  5]\n"
          ]
        }
      ]
    }
  ]
}